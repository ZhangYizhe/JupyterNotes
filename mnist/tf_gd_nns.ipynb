{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "tf_gd_nns.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcc4fa9b-02f4-4276-9dec-5c538a6755f3"
      },
      "source": [
        "# MNIST task achieved by Gradient Descent of Tensorflow"
      ],
      "id": "dcc4fa9b-02f4-4276-9dec-5c538a6755f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51COTxYmnYgU"
      },
      "source": [
        "This note utilised the part ability of Tensorflow (Gradient Descent) to achieve the aim of recognition of number image. The dataset comes from MNIST. It has 60000 training examples and 10000 test examples. The result data (notation as Y) is preprocessed to \"One-Hot\" format. Following this notebook, it will step-by-step take you to create a complete Neural Networks Model."
      ],
      "id": "51COTxYmnYgU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4279c47-67c3-4b12-bf23-cba17acd2bb6"
      },
      "source": [
        "## Load Data"
      ],
      "id": "d4279c47-67c3-4b12-bf23-cba17acd2bb6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b949369-014e-4217-b001-abd9a22d74e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbe23cb-ad4e-4d32-e982-fe32aae9e172"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "np.seterr(divide = 'ignore') \n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "# normalisation\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "def formatY(y):\n",
        "    Y = np.zeros(10)\n",
        "    Y[y] = 1\n",
        "    return Y\n",
        "\n",
        "# reshape\n",
        "X_train = X_train.reshape(60000, 28 ** 2)\n",
        "X_test = X_test.reshape(10000, 28 ** 2)\n",
        "y_train = np.array([formatY(y) for y in y_train])\n",
        "y_test =np.array([formatY(y) for y in y_test])\n",
        "\n",
        "# tensorflow\n",
        "X_train = tf.constant(X_train, dtype=tf.float64)\n",
        "X_test = tf.constant(X_test, dtype=tf.float64)\n",
        "y_train = tf.constant(y_train, dtype=tf.float64)\n",
        "y_test = tf.constant(y_test, dtype=tf.float64)"
      ],
      "id": "2b949369-014e-4217-b001-abd9a22d74e6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10a0bcad-3b88-4f4b-9dc6-6466cd582c2c"
      },
      "source": [
        "## Initialize HyperParameters"
      ],
      "id": "10a0bcad-3b88-4f4b-9dc6-6466cd582c2c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e852a80-bb2a-4a28-b098-4bc74d639995"
      },
      "source": [
        "def inistial_parameters(n, dims):\n",
        "    \n",
        "    W = {}\n",
        "    B = {}\n",
        "    \n",
        "    for i in range(len(dims)):\n",
        "        dim = dims[i]\n",
        "        if i == 0:\n",
        "            w =  np.random.rand(n, dim) * 1e-3 #* (np.sqrt(2 / dim))\n",
        "            W['W' + str(i + 1)] = tf.constant(w)\n",
        "            b = np.zeros((1, dim))\n",
        "            B['b' + str(i + 1)] = tf.constant(b)\n",
        "        else:\n",
        "            w = np.random.rand(dims[i-1], dim) * 1e-3 #* (np.sqrt(2 / dim))\n",
        "            W['W' + str(i + 1)] = tf.constant(w)\n",
        "            b = np.zeros((1, dim))\n",
        "            B['b' + str(i + 1)] = tf.constant(b)\n",
        "            \n",
        "    return {\n",
        "        'W' : W,\n",
        "        'b' : B\n",
        "    }"
      ],
      "id": "5e852a80-bb2a-4a28-b098-4bc74d639995",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "055801a3-ee6f-47cb-b55e-23acaeea2844"
      },
      "source": [
        "## Linear Regression"
      ],
      "id": "055801a3-ee6f-47cb-b55e-23acaeea2844"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cafd6ea0-1e3a-4d0e-a1dc-4336b5749ad0"
      },
      "source": [
        "def linear(X, W, b):\n",
        "    return np.dot(X, W) + b"
      ],
      "id": "cafd6ea0-1e3a-4d0e-a1dc-4336b5749ad0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "404e661c-d419-4943-968a-ad7c08b592fb"
      },
      "source": [
        "## ReLU"
      ],
      "id": "404e661c-d419-4943-968a-ad7c08b592fb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "914c3811-2ef8-49ec-86aa-c66c557e3dff"
      },
      "source": [
        "def relu(X):\n",
        "    return np.maximum(X, 0)"
      ],
      "id": "914c3811-2ef8-49ec-86aa-c66c557e3dff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c6b0999-7d53-4d33-99ab-cdf1d9d93ae7"
      },
      "source": [
        "## Softmax"
      ],
      "id": "7c6b0999-7d53-4d33-99ab-cdf1d9d93ae7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9109201-3886-4d8b-8fa8-1519f6b7d6f6"
      },
      "source": [
        "def softmax(X):\n",
        "    return np.exp(X) / (np.sum(np.exp(X), axis=1, keepdims=True)) "
      ],
      "id": "b9109201-3886-4d8b-8fa8-1519f6b7d6f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "368ad0d4-ea75-4014-ac38-27aaffde52d8"
      },
      "source": [
        "## Activation function"
      ],
      "id": "368ad0d4-ea75-4014-ac38-27aaffde52d8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fab912d0-eadf-4a1a-ac23-bfaa9ed5f5e2"
      },
      "source": [
        "def activation(A_prev, W, b, active):\n",
        "    \"\"\"\n",
        "    activation - relu/softmax\n",
        "    \"\"\"\n",
        "    \n",
        "    if active == 'relu':\n",
        "        Z = linear(A_prev, W, b)\n",
        "        A = relu(Z)\n",
        "    elif active == 'softmax':\n",
        "        Z = linear(A_prev, W, b)\n",
        "        A = softmax(Z)\n",
        "        \n",
        "    return A, Z"
      ],
      "id": "fab912d0-eadf-4a1a-ac23-bfaa9ed5f5e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0819e1b9-278c-408d-bbe6-2abfba6b427d"
      },
      "source": [
        "## L model forward"
      ],
      "id": "0819e1b9-278c-408d-bbe6-2abfba6b427d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2240fd83-3f3a-4811-b961-087df512973b"
      },
      "source": [
        "def L_model_forward(X, W, b):\n",
        "    A = X\n",
        "    L = len(b)\n",
        "    # caches = {}\n",
        "    \n",
        "    # caches['A0'] = A\n",
        "    \n",
        "    for i in range(1, L):\n",
        "        A_prev = A\n",
        "        \n",
        "        A, Z = activation(A_prev, W['W' + str(i)], b['b' + str(i)], 'relu')\n",
        "        # caches['A' + str(i)] = A\n",
        "        # caches['Z' + str(i)] = Z\n",
        "        \n",
        "    AL, ZL = activation(A, W['W' + str(L)], b['b' + str(L)], 'softmax')\n",
        "    # caches['A' + str(L)] = AL\n",
        "    # caches['Z' + str(L)] = ZL\n",
        "    \n",
        "    return AL"
      ],
      "id": "2240fd83-3f3a-4811-b961-087df512973b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45f5f06e-6630-441f-8812-3a9a8b52b7d1"
      },
      "source": [
        "## CrossEntropy"
      ],
      "id": "45f5f06e-6630-441f-8812-3a9a8b52b7d1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fdb9eb2-d97b-4381-bee9-928bcc3d2a65"
      },
      "source": [
        "def crossEntropy(haty, Y):\n",
        "    m = haty.shape[0]\n",
        "\n",
        "    ce = np.sum(Y * np.log(haty))\n",
        "\n",
        "    return - ce / m\n"
      ],
      "id": "0fdb9eb2-d97b-4381-bee9-928bcc3d2a65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1bcf669-1f5d-42f3-a401-7ef1bc445a8b"
      },
      "source": [
        "## Train"
      ],
      "id": "e1bcf669-1f5d-42f3-a401-7ef1bc445a8b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvuZ9TbPpWmd"
      },
      "source": [
        "SGDRange function will split data to subsets for achievement of SGD."
      ],
      "id": "kvuZ9TbPpWmd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi_kVJAGb9-K"
      },
      "source": [
        "def SGDRange(m, setpsize):\n",
        "  sum = m\n",
        "  setpsize = setpsize\n",
        "\n",
        "  rangeArr = []\n",
        "\n",
        "  for i in range(0, (sum // setpsize) * setpsize, setpsize):\n",
        "    rangeArr.append([i, i + setpsize])\n",
        "    \n",
        "  if sum % setpsize != 0:\n",
        "    lastone = sum // setpsize * setpsize\n",
        "    rangeArr.append([lastone, lastone + sum % setpsize])\n",
        "  return rangeArr\n",
        "\n",
        "# debug\n",
        "# rangeArr = SGDRange(124, 50)\n",
        "# print(rangeArr)"
      ],
      "id": "Pi_kVJAGb9-K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dcbf689-134d-4595-89b5-ac79fc5a302b",
        "outputId": "e9c61894-9f8f-4db0-d8fe-8b532ef5019b"
      },
      "source": [
        "n = X_train.shape[1]\n",
        "alpha = 0.1\n",
        "\n",
        "dims = [512, 10]\n",
        "L = len(dims)\n",
        "\n",
        "parameters = inistial_parameters(n, dims)\n",
        "W = parameters['W']\n",
        "b = parameters['b']\n",
        "\n",
        "# AL, caches = L_model_forward(X_train, W, b)\n",
        "\n",
        "cost_train = []\n",
        "cost_test = []\n",
        "\n",
        "def backpropagation(X, y):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as g:\n",
        "        \n",
        "        for i in range(1, L + 1):\n",
        "            g.watch(W['W' + str(i)])\n",
        "            g.watch(b['b' + str(i)])\n",
        "\n",
        "        # ReLU\n",
        "        A_previous = X\n",
        "        for i in range(1, L):\n",
        "            L_hidden = tf.experimental.numpy.dot(A_previous, W['W' + str(i)]) + b['b' + str(i)]\n",
        "            A_previous = tf.math.maximum(L_hidden, 0) \n",
        "\n",
        "        # softmax\n",
        "        LL = tf.experimental.numpy.dot(A_previous, W['W' + str(L)]) + b['b' + str(L)]\n",
        "        AL = (tf.experimental.numpy.exp(LL)) / (tf.experimental.numpy.sum(tf.experimental.numpy.exp(LL), axis=1, keepdims=True)) \n",
        "\n",
        "        # cost function\n",
        "        J = - tf.experimental.numpy.sum(y * tf.experimental.numpy.log(AL)) / m\n",
        "    \n",
        "    for i in range(1, L + 1):\n",
        "        \n",
        "        dJ_W = g.gradient(J, W['W' + str(i)])\n",
        "        dJ_b = g.gradient(J, b['b' + str(i)])\n",
        "\n",
        "        W['W' + str(i)] = W['W' + str(i)] - alpha * dJ_W\n",
        "        b['b' + str(i)] = b['b' + str(i)] - alpha * dJ_b\n",
        "\n",
        "iteration = 40\n",
        "for i in range(iteration):\n",
        "\n",
        "  rangeArr = SGDRange(X_train.shape[0], 512)\n",
        "  for index in rangeArr:\n",
        "    backpropagation(X_train[index[0]:index[1]], y_train[index[0]:index[1]])\n",
        "\n",
        "  cost_train.append(crossEntropy(L_model_forward(X_train, W, b), y_train))\n",
        "  cost_test.append(crossEntropy(L_model_forward(X_test, W, b), y_test))\n",
        "\n",
        "  if i % 5 == 0 or i == iteration - 1:\n",
        "    print('====enoch == {enoch}===='.format(enoch=i))\n",
        "    print('cost_train: {cost_train}'.format(cost_train=cost_train[i]))\n",
        "    print('cost_test: {cost_test}'.format(cost_test=cost_test[i]))\n",
        "\n"
      ],
      "id": "1dcbf689-134d-4595-89b5-ac79fc5a302b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====enoch == 0====\n",
            "cost_train: 1.8709932150979665\n",
            "cost_test: 1.8652161279462922\n",
            "====enoch == 5====\n",
            "cost_train: 0.33255059069228365\n",
            "cost_test: 0.3201571259964204\n",
            "====enoch == 10====\n",
            "cost_train: 0.2601728515968153\n",
            "cost_test: 0.25315654257532205\n",
            "====enoch == 15====\n",
            "cost_train: 0.21736805206427454\n",
            "cost_test: 0.21382235900617397\n",
            "====enoch == 20====\n",
            "cost_train: 0.18549993119361605\n",
            "cost_test: 0.18474472488356808\n",
            "====enoch == 25====\n",
            "cost_train: 0.16070849438859428\n",
            "cost_test: 0.16264182783442965\n",
            "====enoch == 30====\n",
            "cost_train: 0.1410160678928834\n",
            "cost_test: 0.14566523833924244\n",
            "====enoch == 35====\n",
            "cost_train: 0.12509860787396332\n",
            "cost_test: 0.13243227396503532\n",
            "====enoch == 39====\n",
            "cost_train: 0.11442393794352002\n",
            "cost_test: 0.12386539380015027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "a2e96db6-42cc-47d6-bea3-3680eadcff72",
        "outputId": "f4f36b9e-f440-4b6b-da86-12a32766eee2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cost_train[3:], label=\"Train Data\")\n",
        "plt.plot(cost_test[3:], label=\"Validation Data\")\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "a2e96db6-42cc-47d6-bea3-3680eadcff72",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf940ea8-8210-49ba-b055-1e0b8b31e426"
      },
      "source": [
        "## get correct percentage"
      ],
      "id": "cf940ea8-8210-49ba-b055-1e0b8b31e426"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92906d1e-923f-482b-a253-b46930f1e792",
        "outputId": "83fb0161-9201-43a8-bdc1-4158884acb59"
      },
      "source": [
        "def getCorrectPercentage(X, y):\n",
        "  m = len(X)\n",
        "  hatys = L_model_forward(X, W, b)\n",
        "  hatys = np.array([formatY(np.argmax(y)) for y in hatys])\n",
        "  corrent_num = np.sum(y * hatys)\n",
        "  return corrent_num / m\n",
        "\n",
        "print(getCorrectPercentage(X_train, y_train))\n",
        "print(getCorrectPercentage(X_test, y_test))"
      ],
      "id": "92906d1e-923f-482b-a253-b46930f1e792",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9683333333333334\n",
            "0.9637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "cfcb3550-6dff-4569-8203-9906b78f66ef",
        "outputId": "65bcdec6-a454-45c9-bcf9-853589131032"
      },
      "source": [
        "## Test\n",
        "index = 1\n",
        "single_label = np.where(y_test[index] == 1)[0]\n",
        "single_Image = X_test[index].numpy()\n",
        "single_Image_r = single_Image.reshape((28, 28))\n",
        "test = L_model_forward(single_Image, W, b)\n",
        "print(test)\n",
        "print(np.argmax(test))\n",
        "plt.title('Label is {label}'.format(label=single_label))\n",
        "plt.imshow(single_Image_r, cmap='gray')\n",
        "plt.show()"
      ],
      "id": "cfcb3550-6dff-4569-8203-9906b78f66ef",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00120699 0.00002506 0.98845701 0.00928377 0.         0.00037926\n",
            "  0.00032382 0.         0.00032408 0.        ]]\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "602a26e0-d703-4314-9810-fd4a1b32060d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "7a140f07-f445-4b89-ef8d-720bbaa1caa9"
      },
      "source": [
        "test_data = pd.read_csv('/content/test.csv')\n",
        "test_data = test_data / 255\n",
        "test_data.describe()"
      ],
      "id": "602a26e0-d703-4314-9810-fd4a1b32060d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.000655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012833</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.005703</td>\n",
              "      <td>0.003319</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>0.000999</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000789</td>\n",
              "      <td>0.001275</td>\n",
              "      <td>0.001438</td>\n",
              "      <td>0.001836</td>\n",
              "      <td>0.002311</td>\n",
              "      <td>0.002576</td>\n",
              "      <td>0.002234</td>\n",
              "      <td>0.001820</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.006142</td>\n",
              "      <td>0.005935</td>\n",
              "      <td>0.010488</td>\n",
              "      <td>0.012613</td>\n",
              "      <td>0.017841</td>\n",
              "      <td>0.021453</td>\n",
              "      <td>...</td>\n",
              "      <td>0.098869</td>\n",
              "      <td>0.083294</td>\n",
              "      <td>0.065269</td>\n",
              "      <td>0.049561</td>\n",
              "      <td>0.039074</td>\n",
              "      <td>0.027575</td>\n",
              "      <td>0.011924</td>\n",
              "      <td>0.004963</td>\n",
              "      <td>0.000516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002512</td>\n",
              "      <td>0.008765</td>\n",
              "      <td>0.009780</td>\n",
              "      <td>0.014815</td>\n",
              "      <td>0.019400</td>\n",
              "      <td>0.024560</td>\n",
              "      <td>0.030254</td>\n",
              "      <td>0.032328</td>\n",
              "      <td>0.035192</td>\n",
              "      <td>0.041132</td>\n",
              "      <td>0.043959</td>\n",
              "      <td>0.040016</td>\n",
              "      <td>0.036871</td>\n",
              "      <td>0.030897</td>\n",
              "      <td>0.021464</td>\n",
              "      <td>0.014184</td>\n",
              "      <td>0.007112</td>\n",
              "      <td>0.004726</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.925490</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.996078</td>\n",
              "      <td>0.996078</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992157</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.086275</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0.960784</td>\n",
              "      <td>0.996078</td>\n",
              "      <td>0.996078</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996078</td>\n",
              "      <td>0.992157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992157</td>\n",
              "      <td>0.996078</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        pixel0   pixel1   pixel2  ...  pixel781  pixel782  pixel783\n",
              "count  28000.0  28000.0  28000.0  ...   28000.0   28000.0   28000.0\n",
              "mean       0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "std        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "min        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "25%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "50%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "75%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "max        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b98732a-a149-4baf-886c-455d29cdea2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746761a9-7073-4d81-b265-d71f1a49c844"
      },
      "source": [
        "hatys = L_model_forward(test_data, W, b)\n",
        "hatys = np.array([np.argmax(y) for y in hatys])\n",
        "    \n",
        "hatys = pd.DataFrame(zip(range(1, len(hatys) + 1), hatys), columns=['ImageId', 'Label'])\n",
        "print(hatys)"
      ],
      "id": "0b98732a-a149-4baf-886c-455d29cdea2e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       ImageId  Label\n",
            "0            1      2\n",
            "1            2      0\n",
            "2            3      9\n",
            "3            4      9\n",
            "4            5      3\n",
            "...        ...    ...\n",
            "27995    27996      9\n",
            "27996    27997      7\n",
            "27997    27998      3\n",
            "27998    27999      9\n",
            "27999    28000      2\n",
            "\n",
            "[28000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9a956eb-dd4e-43b9-8e66-99bb864597c6"
      },
      "source": [
        "hatys.to_csv('submission.csv', index=False)"
      ],
      "id": "c9a956eb-dd4e-43b9-8e66-99bb864597c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ca43bdd-64ca-4685-b1ac-8d85b330ee28"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# save pickle\n",
        "filename = 'model.pkl'\n",
        "model = {'W': W, 'b': b}\n",
        "pickle.dump( model, open( filename, \"wb\" ) )"
      ],
      "id": "5ca43bdd-64ca-4685-b1ac-8d85b330ee28",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJdDTBYxtDtW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70cf560-2c3e-4b5e-c76f-6fa0d92a9353"
      },
      "source": [
        "# load pickle\n",
        "model = pickle.load( open( filename, \"rb\" ) )\n",
        "print(model)"
      ],
      "id": "iJdDTBYxtDtW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'W': {'W1': <tf.Tensor: shape=(784, 512), dtype=float64, numpy=\n",
            "array([[0.00059625, 0.0003933 , 0.00086785, ..., 0.00004858, 0.00013379,\n",
            "        0.00072218],\n",
            "       [0.00008176, 0.00020808, 0.00087247, ..., 0.00031483, 0.00028947,\n",
            "        0.00087381],\n",
            "       [0.00060837, 0.00019523, 0.00022169, ..., 0.00024983, 0.00056518,\n",
            "        0.00084179],\n",
            "       ...,\n",
            "       [0.00051276, 0.00079527, 0.00073196, ..., 0.00087327, 0.0001117 ,\n",
            "        0.00095047],\n",
            "       [0.00025562, 0.00063432, 0.00098423, ..., 0.00098407, 0.00010416,\n",
            "        0.00084661],\n",
            "       [0.00063168, 0.00042199, 0.00028202, ..., 0.00071671, 0.00044832,\n",
            "        0.00074504]])>, 'W2': <tf.Tensor: shape=(512, 10), dtype=float64, numpy=\n",
            "array([[-0.03960964, -0.05654916, -0.09718664, ..., -0.08110619,\n",
            "         0.02034825, -0.04291938],\n",
            "       [-0.03432546, -0.08943601,  0.2000573 , ...,  0.00238561,\n",
            "         0.05304944, -0.04931454],\n",
            "       [-0.01129258, -0.0534653 ,  0.09417206, ..., -0.05689573,\n",
            "         0.03362151, -0.0435891 ],\n",
            "       ...,\n",
            "       [ 0.10734552, -0.01945019,  0.14823176, ...,  0.02524827,\n",
            "        -0.24190388, -0.01543422],\n",
            "       [ 0.03953437, -0.07087854,  0.1340102 , ..., -0.10501415,\n",
            "         0.17398236, -0.01249852],\n",
            "       [ 0.00249688,  0.12856071,  0.04746972, ...,  0.29250065,\n",
            "        -0.28963695, -0.22801768]])>}, 'b': {'b1': <tf.Tensor: shape=(1, 512), dtype=float64, numpy=\n",
            "array([[ 0.02072745, -0.03056966,  0.01397763, -0.00809901, -0.03333529,\n",
            "        -0.05454291,  0.02327907, -0.00804079,  0.00295779,  0.07369145,\n",
            "         0.02193847,  0.01844917, -0.0117287 ,  0.00293504,  0.00158437,\n",
            "         0.01021031,  0.02201981, -0.008572  , -0.00686714, -0.03042898,\n",
            "        -0.0467361 , -0.00274912, -0.02004973, -0.06772965, -0.040414  ,\n",
            "        -0.04007099,  0.00469342,  0.0210309 ,  0.02385286, -0.01219788,\n",
            "         0.05573815, -0.04325021,  0.02167653, -0.03150533, -0.02654419,\n",
            "        -0.03728009, -0.01740934, -0.00396748, -0.01667078,  0.03044277,\n",
            "         0.02396024, -0.06147267,  0.01788525, -0.00822536,  0.01305907,\n",
            "        -0.00034865,  0.01719415,  0.02711731,  0.02650969, -0.01439074,\n",
            "        -0.05467651,  0.00855126,  0.02262341,  0.0129343 ,  0.02583952,\n",
            "         0.04223486, -0.01121538, -0.02263712, -0.01784911, -0.0634238 ,\n",
            "        -0.02767887, -0.01758701, -0.05178466, -0.08532347, -0.03503103,\n",
            "         0.00962263,  0.02053058, -0.03610436,  0.00324442,  0.02304501,\n",
            "        -0.02352031,  0.00722878, -0.01017155, -0.00552404,  0.07291367,\n",
            "        -0.08256182, -0.03466863, -0.0017959 , -0.03035741,  0.02781346,\n",
            "        -0.01632649, -0.01423055, -0.06933931,  0.0001537 , -0.03394266,\n",
            "         0.01798842, -0.0281549 ,  0.00481885, -0.06053006,  0.01901832,\n",
            "        -0.00655027,  0.0003864 , -0.01079044, -0.00842045, -0.00152574,\n",
            "         0.05710533,  0.00084059,  0.04748883,  0.04810647,  0.01739124,\n",
            "         0.00684283, -0.00104981,  0.02546332,  0.05167912, -0.02985868,\n",
            "         0.04818039, -0.05948836, -0.01350072, -0.02063938, -0.00485244,\n",
            "         0.01467063, -0.00406779, -0.02832448,  0.03274687, -0.02060638,\n",
            "        -0.02015362,  0.01605344, -0.02683778,  0.00552935,  0.00069411,\n",
            "         0.00330884, -0.02870097, -0.04881415,  0.01734834,  0.01524246,\n",
            "         0.01167802, -0.02920074, -0.00151885,  0.03042459, -0.02987662,\n",
            "        -0.03506827,  0.0122383 ,  0.00996653, -0.01880057, -0.03126483,\n",
            "         0.02226148, -0.00828429, -0.03198876,  0.01995651,  0.01385931,\n",
            "         0.01907225,  0.00698054,  0.00940772, -0.06034565,  0.01397744,\n",
            "        -0.05175624, -0.01664877,  0.04909491, -0.00811451,  0.02832631,\n",
            "        -0.07852087, -0.00410647, -0.04723584, -0.0164143 ,  0.03090205,\n",
            "         0.0008016 , -0.00112726, -0.01851955,  0.01645981,  0.01647678,\n",
            "         0.02958436,  0.05299844, -0.08105761, -0.04230007, -0.03338225,\n",
            "        -0.04162971, -0.02192218,  0.1774729 , -0.00499334, -0.03868554,\n",
            "        -0.0032204 , -0.06258108,  0.02471575, -0.03038365, -0.00350793,\n",
            "        -0.0032171 ,  0.04163017, -0.03901996,  0.00838094,  0.01066884,\n",
            "        -0.00551922,  0.01289209,  0.0063768 ,  0.00538542,  0.04294586,\n",
            "        -0.051114  ,  0.00402369, -0.02311449, -0.00558213, -0.0135224 ,\n",
            "         0.00583686, -0.04268232, -0.00213663, -0.02137862, -0.02610767,\n",
            "        -0.00795984, -0.04758675, -0.02307838, -0.01692969, -0.0341065 ,\n",
            "        -0.02008455, -0.02820515, -0.02229632, -0.01049414, -0.03248074,\n",
            "        -0.04921945,  0.02150285, -0.01062337, -0.04246236, -0.00180079,\n",
            "        -0.02886464, -0.03497037,  0.0124342 , -0.06326921,  0.0176704 ,\n",
            "        -0.00209693, -0.0158232 , -0.04093107, -0.03304177, -0.0347241 ,\n",
            "        -0.01769868, -0.02128377,  0.02058781,  0.00699343,  0.01299769,\n",
            "        -0.05167959, -0.05420082,  0.04090739, -0.04165764, -0.0002271 ,\n",
            "        -0.04198046, -0.01580994,  0.01768722,  0.03650061,  0.01562672,\n",
            "         0.01801793, -0.00654574, -0.02773598, -0.05245456, -0.03773731,\n",
            "        -0.00040723,  0.01405537,  0.02402308, -0.03172035, -0.0029549 ,\n",
            "         0.00463793,  0.01052253, -0.00307604, -0.00528455, -0.02263257,\n",
            "        -0.02423025,  0.05470357,  0.0329262 , -0.04081319,  0.06432141,\n",
            "        -0.01855599,  0.01795556, -0.0139412 ,  0.00215467, -0.04390305,\n",
            "        -0.00552161, -0.01120556,  0.00436954, -0.01167537,  0.02638754,\n",
            "         0.01007043,  0.05379481, -0.01686714,  0.00759637, -0.02441703,\n",
            "         0.06631409,  0.00399242,  0.0076807 ,  0.03796253, -0.01244002,\n",
            "         0.10132756,  0.01912863, -0.06199131, -0.03577964,  0.01370089,\n",
            "        -0.04526629, -0.01634432,  0.00663827,  0.00343735, -0.05504188,\n",
            "        -0.0214072 , -0.0316878 ,  0.01022986, -0.00473628,  0.01982597,\n",
            "        -0.00509015,  0.06304376,  0.00292887,  0.05311977,  0.02260266,\n",
            "         0.00061795, -0.02997192, -0.01891742,  0.02541568, -0.00140837,\n",
            "        -0.02530863,  0.06064758,  0.02338681, -0.03529669,  0.05901951,\n",
            "        -0.01686589, -0.0226666 ,  0.03574256, -0.06590957,  0.02491112,\n",
            "        -0.01086008, -0.02263613,  0.04289202, -0.00062748, -0.03617077,\n",
            "         0.02096292, -0.01165695,  0.00127765,  0.01865649, -0.00982678,\n",
            "         0.00088902, -0.01621563,  0.05424653,  0.01483037, -0.03204671,\n",
            "        -0.0255433 ,  0.02244775, -0.01462965,  0.04947723, -0.00476764,\n",
            "        -0.05473928,  0.02878031, -0.01115744, -0.01867648, -0.00258718,\n",
            "         0.029266  , -0.02144308, -0.00456811, -0.02265337, -0.00545606,\n",
            "        -0.00233405,  0.00960281, -0.01645127, -0.02014594,  0.06515093,\n",
            "         0.03902895,  0.00259602,  0.01836292, -0.03634065, -0.01003641,\n",
            "        -0.03671071, -0.01661037, -0.04352357, -0.01748934,  0.04079131,\n",
            "        -0.04027163, -0.02752806, -0.00230911, -0.03190623, -0.01826163,\n",
            "         0.01295771, -0.01278589,  0.03772249, -0.01699796, -0.01442682,\n",
            "        -0.0241875 ,  0.02487754, -0.00561234,  0.09988748,  0.04450508,\n",
            "        -0.02404088,  0.00325842,  0.00620358, -0.01146309, -0.00019505,\n",
            "        -0.04762644,  0.01860721, -0.03853451, -0.0439892 , -0.02733506,\n",
            "        -0.04809791, -0.04739829,  0.01841409, -0.00173275,  0.0809186 ,\n",
            "         0.011853  , -0.00418246,  0.00547004,  0.04229141,  0.03238233,\n",
            "         0.04544926, -0.01712115,  0.02593119, -0.01319523,  0.00057623,\n",
            "         0.00377981,  0.12328108,  0.03671302, -0.00655302, -0.00901404,\n",
            "        -0.00326136,  0.00421793, -0.00323527, -0.0387654 , -0.03140577,\n",
            "        -0.00198094,  0.03482401, -0.06774298,  0.02597156, -0.0060026 ,\n",
            "        -0.01553432,  0.00983138,  0.01311155, -0.02417338,  0.0001316 ,\n",
            "         0.07176859, -0.02164231,  0.00460644,  0.00555661,  0.03435782,\n",
            "        -0.00381416, -0.06096258,  0.03844403,  0.05341957,  0.04057111,\n",
            "         0.0190923 ,  0.05570809,  0.02192323, -0.0076799 ,  0.00196662,\n",
            "        -0.04886975,  0.02484096,  0.04055536,  0.03487908, -0.02359281,\n",
            "        -0.07230501, -0.00084177,  0.00359009, -0.01736483, -0.00999311,\n",
            "        -0.01573415,  0.00250884, -0.00141794,  0.04396002,  0.034608  ,\n",
            "         0.01445604, -0.01521182, -0.02356722, -0.01625351,  0.01882641,\n",
            "         0.06491976, -0.00608911,  0.02977449, -0.01716025, -0.07352758,\n",
            "        -0.0028161 , -0.01489401,  0.06440341, -0.05982883,  0.00699739,\n",
            "         0.00835736, -0.02004153, -0.01298326, -0.06505857,  0.0108975 ,\n",
            "        -0.04580104, -0.05021769,  0.01965448, -0.01103121,  0.0384003 ,\n",
            "        -0.02556769, -0.01329301,  0.00452046, -0.01831697,  0.0323593 ,\n",
            "         0.00594669,  0.00397614, -0.02112345,  0.07730966, -0.01416537,\n",
            "        -0.03604139,  0.03709916,  0.04236828, -0.00245849, -0.03921484,\n",
            "         0.03367062, -0.09033704, -0.01812143,  0.04352699,  0.01741083,\n",
            "        -0.0149807 ,  0.01217949,  0.00794027, -0.02821235, -0.02040648,\n",
            "        -0.03029479,  0.00805099,  0.01321192,  0.00384945, -0.00592157,\n",
            "         0.01224069,  0.0213846 , -0.00867941, -0.03435543, -0.01860772,\n",
            "         0.10402029,  0.04776011, -0.01524056,  0.00080282, -0.01205634,\n",
            "        -0.02810165,  0.0513714 ]])>, 'b2': <tf.Tensor: shape=(1, 10), dtype=float64, numpy=\n",
            "array([[-1.03596642,  1.11195099, -0.2117684 , -0.32287018,  0.25903696,\n",
            "         0.32046788, -0.22610707,  0.41244605, -0.49724109,  0.19005128]])>}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3zsExwxLNIc"
      },
      "source": [
        ""
      ],
      "id": "t3zsExwxLNIc",
      "execution_count": null,
      "outputs": []
    }
  ]
}